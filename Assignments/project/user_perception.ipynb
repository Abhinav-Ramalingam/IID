{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0576065",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ac0cc8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8f8179df-f38b-4275-9b59-2293bef2946f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "8f8179df-f38b-4275-9b59-2293bef2946f",
        "outputId": "4f7d6c25-ea7c-4e58-be51-d572cc1662ae"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from feat import Detector\n",
        "from IPython.display import Image\n",
        "from feat.utils import FEAT_EMOTION_COLUMNS\n",
        "\n",
        "detector = Detector(device=\"cpu\")\n",
        "\n",
        "# Define the root directory of your dataset\n",
        "dataset_dir = \"DiffusionFER/DiffusionFER/DiffusionEmotion_S\"\n",
        "aus_csv_path = os.path.join(os.getcwd(), \"DiffusionFER/DiffusionFER/DiffusionEmotion_S/result.csv\")\n",
        "results=[]\n",
        "# Iterate through each emotion folder\n",
        "folders = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]\n",
        "#print(f\"Emotion folders found: {folders}\")\n",
        "\n",
        "face_tracker = cv2.CascadeClassifier(\"frontal_face_features.xml\") # loading a pre-trained face detection classifier from an XML file\n",
        "\n",
        "# Loop through each emotion folder\n",
        "for emotion in folders:\n",
        "    emotion_folder = os.path.join(dataset_dir, emotion)\n",
        "    image_files = [f for f in os.listdir(emotion_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    # Process each image in the folder\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(emotion_folder, image_file)\n",
        "\n",
        "        frame = cv2.imread(image_path)  # Load the image using OpenCV (as BGR)\n",
        "\n",
        "        faces = detector.detect_faces(frame) # Detects face and returns coordinates\n",
        "        landmarks = detector.detect_landmarks(frame, faces) # Detects facial landmarks\n",
        "        emotions = detector.detect_emotions(frame, faces, landmarks) # analyses face landmarks and predicts emotions expressed\n",
        "        aus = detector.detect_aus(frame, landmarks)\n",
        "\n",
        "        # assume only one face captured\n",
        "        faces = faces[0]\n",
        "        landmarks = landmarks[0]\n",
        "        emotions = emotions[0]  # Convert the first element of emotions to a numpy array\n",
        "        aus=aus[0]\n",
        "\n",
        "        #strongest_emotion = emotions.argmax(axis=1)\n",
        "\n",
        "        for face, landmark, emotion, au_activation in zip(faces, landmarks, emotions,aus):\n",
        "\n",
        "            (x0, y0, x1, y1, p) = face\n",
        "\n",
        "            # cv2.rectangle(frame, (int(x0), int(y0)), (int(x1), int(y1)), (0, 0, 255), 3)\n",
        "            # cv2.putText(frame, FEAT_EMOTION_COLUMNS[top_emo], (int(x0), int(y0 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
        "\n",
        "            # Remove the file extension\n",
        "            filename = os.path.splitext(image_file)[0]\n",
        "            result = {'file': image_file }\n",
        "            result.update({f\"AU_{j}\": au for j, au in enumerate(au_activation)})\n",
        "            results.append(result)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(aus_csv_path, index=False)\n",
        "print(f\"AU activations saved to {aus_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fa0f54-745f-4c9c-9423-d9cb926fb33e",
      "metadata": {
        "id": "73fa0f54-745f-4c9c-9423-d9cb926fb33e"
      },
      "outputs": [],
      "source": [
        "dataset_sheet=os.path.join(os.getcwd(), \"DiffusionFER/DiffusionFER/DiffusionEmotion_S/dataset_sheet.csv\")\n",
        "dataset_sheet = pd.read_csv(dataset_sheet)\n",
        "# Extract the filenames from the 'subDirectory_filePath' column in dataset_sheet\n",
        "dataset_sheet['file'] = dataset_sheet['subDirectory_filePath'].apply(lambda x: x.split('/')[-1])\n",
        "\n",
        "# Merge the two DataFrames on the 'file' column\n",
        "merged_data = pd.merge(results_df, dataset_sheet, on='file', how='inner')\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_data.to_csv(aus_csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27c40bc-accd-48d1-a2c6-a854cde9b762",
      "metadata": {
        "id": "b27c40bc-accd-48d1-a2c6-a854cde9b762"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Classify the data based on valence values\n",
        "merged_data['valence'] = pd.to_numeric(merged_data['valence'], errors='coerce')\n",
        "positive_data = merged_data[merged_data['valence'] > 0]\n",
        "negative_data = merged_data[merged_data['valence'] < 0]\n",
        "neutral_data = merged_data[merged_data['valence'] == 0]  # Neutral data\n",
        "\n",
        "# Extract Action Unit columns\n",
        "au_columns = [col for col in merged_data.columns if col.startswith('AU')]\n",
        "\n",
        "# Calculate mean for each condition\n",
        "positive_means = positive_data[au_columns].mean()\n",
        "negative_means = negative_data[au_columns].mean()\n",
        "neutral_means = neutral_data[au_columns].mean()\n",
        "\n",
        "# Print the means for debugging or analysis\n",
        "print(\"Positive AUs Mean:\")\n",
        "print(positive_means)\n",
        "print(\"\\nNegative AUs Mean:\")\n",
        "print(negative_means)\n",
        "print(\"\\nNeutral AUs Mean:\")\n",
        "print(neutral_means)\n",
        "\n",
        "# Calculate absolute differences (positive vs. negative)\n",
        "abs_diff_pos_neg = (positive_means - negative_means).abs()\n",
        "abs_diff_pos_neu = (positive_means - neutral_means).abs()\n",
        "abs_diff_neg_neu = (negative_means - neutral_means).abs()\n",
        "\n",
        "# Sort the differences for each comparison\n",
        "sorted_diff_pos_neg = abs_diff_pos_neg.sort_values(ascending=False)\n",
        "sorted_diff_pos_neu = abs_diff_pos_neu.sort_values(ascending=False)\n",
        "sorted_diff_neg_neu = abs_diff_neg_neu.sort_values(ascending=False)\n",
        "\n",
        "# Plot absolute differences\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(sorted_diff_pos_neg.index, sorted_diff_pos_neg.values, color='blue', label='Positive vs Negative')\n",
        "plt.scatter(sorted_diff_pos_neu.index, sorted_diff_pos_neu.values, color='green', label='Positive vs Neutral')\n",
        "plt.scatter(sorted_diff_neg_neu.index, sorted_diff_neg_neu.values, color='red', label='Negative vs Neutral')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Action Units (AUs)')\n",
        "plt.ylabel('Absolute Difference of Means')\n",
        "plt.title('Absolute Difference in AU Means Across Conditions')\n",
        "plt.legend()\n",
        "\n",
        "# Save the graph to the folder\n",
        "output_path = os.path.join(os.getcwd(), \"DiffusionFER/DiffusionFER/DiffusionEmotion_S/au_visualization.png\")\n",
        "plt.savefig(output_path, format='png')  # Save the graph\n",
        "plt.show()\n",
        "print(f\"Graph saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec16add-86a2-4e6e-b846-5ad52d56ca85",
      "metadata": {
        "id": "8ec16add-86a2-4e6e-b846-5ad52d56ca85"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
